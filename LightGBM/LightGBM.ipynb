{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "name": "lgbm-baseline.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "G0I-1HdB4hwf",
    "2Tm5yPcW4hwh",
    "fXVWOfSX4hwj",
    "ZTO0B9av4hwm",
    "h8Qazmx44hwp",
    "N-SY9Hk24hwr"
   ]
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from helper_functions import *\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)"
   ],
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2022-01-05T14:43:48.692389Z",
     "iopub.execute_input": "2022-01-05T14:43:48.692981Z",
     "iopub.status.idle": "2022-01-05T14:43:52.409046Z",
     "shell.execute_reply.started": "2022-01-05T14:43:48.692913Z",
     "shell.execute_reply": "2022-01-05T14:43:52.408142Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "lPHuUG7Q4hwY",
    "outputId": "dae67059-9cbe-46ad-ea28-3ec68a026f8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "category_columns = []\n",
    "feature_columns = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading (Train dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "full_train_df = pd.read_feather(\"./data/train_full.feather\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = full_train_df[feature_columns + category_columns]\n",
    "y_train = full_train_df['meter_reading_log1p'].values"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-01-05T14:44:40.902415Z",
     "iopub.execute_input": "2022-01-05T14:44:40.902768Z",
     "iopub.status.idle": "2022-01-05T14:44:40.915577Z",
     "shell.execute_reply.started": "2022-01-05T14:44:40.902712Z",
     "shell.execute_reply": "2022-01-05T14:44:40.914607Z"
    },
    "trusted": true,
    "id": "6buAhK9h4hwo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "number_of_folds = 5\n",
    "# kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "kf_shuffled = KFold(n_splits=number_of_folds, shuffle=True, random_state=666)"
   ],
   "metadata": {
    "id": "OmKLmMRT6Tut",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 15895908 valid 3973978\n",
      "training LGB:\n",
      "[LightGBM] [Info] Total Bins 5765\n",
      "[LightGBM] [Info] Number of data points in the train set: 15895908, number of used features: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubov/Projects/UniPassau/DSLab/ds-lab-21-22/venv/lib/python3.9/site-packages/lightgbm/basic.py:1780: UserWarning:\n",
      "\n",
      "Overriding the parameters from Reference Dataset.\n",
      "\n",
      "/Users/shubov/Projects/UniPassau/DSLab/ds-lab-21-22/venv/lib/python3.9/site-packages/lightgbm/basic.py:1513: UserWarning:\n",
      "\n",
      "categorical_column in param dict is overridden.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 4.217456\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's rmse: 1.5651\tvalid_1's rmse: 1.56528\n",
      "[40]\ttraining's rmse: 1.36491\tvalid_1's rmse: 1.36516\n",
      "[60]\ttraining's rmse: 1.25718\tvalid_1's rmse: 1.25732\n",
      "[80]\ttraining's rmse: 1.17734\tvalid_1's rmse: 1.1774\n",
      "[100]\ttraining's rmse: 1.12822\tvalid_1's rmse: 1.12825\n",
      "[120]\ttraining's rmse: 1.08359\tvalid_1's rmse: 1.08358\n",
      "[140]\ttraining's rmse: 1.03867\tvalid_1's rmse: 1.03861\n",
      "[160]\ttraining's rmse: 1.00081\tvalid_1's rmse: 1.00087\n",
      "[180]\ttraining's rmse: 0.97604\tvalid_1's rmse: 0.976158\n",
      "[200]\ttraining's rmse: 0.958312\tvalid_1's rmse: 0.958544\n",
      "[220]\ttraining's rmse: 0.94298\tvalid_1's rmse: 0.943302\n",
      "[240]\ttraining's rmse: 0.928003\tvalid_1's rmse: 0.928369\n",
      "[260]\ttraining's rmse: 0.918326\tvalid_1's rmse: 0.918757\n",
      "[280]\ttraining's rmse: 0.907911\tvalid_1's rmse: 0.908354\n",
      "[300]\ttraining's rmse: 0.900155\tvalid_1's rmse: 0.900636\n",
      "[320]\ttraining's rmse: 0.89221\tvalid_1's rmse: 0.892712\n",
      "[340]\ttraining's rmse: 0.885064\tvalid_1's rmse: 0.885634\n",
      "[360]\ttraining's rmse: 0.880942\tvalid_1's rmse: 0.881542\n",
      "[380]\ttraining's rmse: 0.875668\tvalid_1's rmse: 0.876378\n",
      "[400]\ttraining's rmse: 0.871331\tvalid_1's rmse: 0.872096\n",
      "[420]\ttraining's rmse: 0.865922\tvalid_1's rmse: 0.866768\n",
      "[440]\ttraining's rmse: 0.861948\tvalid_1's rmse: 0.86286\n",
      "[460]\ttraining's rmse: 0.858257\tvalid_1's rmse: 0.859234\n",
      "[480]\ttraining's rmse: 0.854982\tvalid_1's rmse: 0.856015\n",
      "[500]\ttraining's rmse: 0.850461\tvalid_1's rmse: 0.851566\n",
      "[520]\ttraining's rmse: 0.8462\tvalid_1's rmse: 0.847377\n",
      "[540]\ttraining's rmse: 0.842609\tvalid_1's rmse: 0.843867\n",
      "[560]\ttraining's rmse: 0.839434\tvalid_1's rmse: 0.840776\n",
      "[580]\ttraining's rmse: 0.836229\tvalid_1's rmse: 0.837651\n",
      "[600]\ttraining's rmse: 0.833391\tvalid_1's rmse: 0.834829\n",
      "[620]\ttraining's rmse: 0.829859\tvalid_1's rmse: 0.831379\n",
      "[640]\ttraining's rmse: 0.824946\tvalid_1's rmse: 0.826508\n",
      "[660]\ttraining's rmse: 0.821813\tvalid_1's rmse: 0.823373\n",
      "[680]\ttraining's rmse: 0.818325\tvalid_1's rmse: 0.819847\n",
      "[700]\ttraining's rmse: 0.815419\tvalid_1's rmse: 0.816991\n",
      "[720]\ttraining's rmse: 0.812714\tvalid_1's rmse: 0.814322\n",
      "[740]\ttraining's rmse: 0.81049\tvalid_1's rmse: 0.812123\n",
      "[760]\ttraining's rmse: 0.807621\tvalid_1's rmse: 0.809294\n",
      "[780]\ttraining's rmse: 0.805108\tvalid_1's rmse: 0.806845\n",
      "[800]\ttraining's rmse: 0.803116\tvalid_1's rmse: 0.804883\n",
      "[820]\ttraining's rmse: 0.800663\tvalid_1's rmse: 0.802409\n",
      "[840]\ttraining's rmse: 0.798411\tvalid_1's rmse: 0.800238\n",
      "[860]\ttraining's rmse: 0.79601\tvalid_1's rmse: 0.797869\n",
      "[880]\ttraining's rmse: 0.793185\tvalid_1's rmse: 0.795047\n",
      "[900]\ttraining's rmse: 0.791244\tvalid_1's rmse: 0.793127\n",
      "[920]\ttraining's rmse: 0.78951\tvalid_1's rmse: 0.791408\n",
      "[940]\ttraining's rmse: 0.787006\tvalid_1's rmse: 0.788939\n",
      "[960]\ttraining's rmse: 0.785053\tvalid_1's rmse: 0.787008\n",
      "[980]\ttraining's rmse: 0.781837\tvalid_1's rmse: 0.783867\n",
      "[1000]\ttraining's rmse: 0.779463\tvalid_1's rmse: 0.781504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 0.779463\tvalid_1's rmse: 0.781504\n",
      "best_score defaultdict(<class 'collections.OrderedDict'>, {'training': OrderedDict([('rmse', 0.7794631023841536)]), 'valid_1': OrderedDict([('rmse', 0.7815042344349475)])})\n",
      "train 15895909 valid 3973977\n",
      "training LGB:\n",
      "[LightGBM] [Info] Total Bins 5815\n",
      "[LightGBM] [Info] Number of data points in the train set: 15895909, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 4.217655\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[20]\ttraining's rmse: 1.56719\tvalid_1's rmse: 1.56799\n",
      "[40]\ttraining's rmse: 1.37146\tvalid_1's rmse: 1.37261\n",
      "[60]\ttraining's rmse: 1.26389\tvalid_1's rmse: 1.26536\n",
      "[80]\ttraining's rmse: 1.18675\tvalid_1's rmse: 1.18852\n",
      "[100]\ttraining's rmse: 1.13221\tvalid_1's rmse: 1.13421\n",
      "[120]\ttraining's rmse: 1.08663\tvalid_1's rmse: 1.08882\n",
      "[140]\ttraining's rmse: 1.04306\tvalid_1's rmse: 1.04531\n",
      "[160]\ttraining's rmse: 1.00776\tvalid_1's rmse: 1.01004\n",
      "[180]\ttraining's rmse: 0.980951\tvalid_1's rmse: 0.983233\n",
      "[200]\ttraining's rmse: 0.957132\tvalid_1's rmse: 0.959423\n",
      "[220]\ttraining's rmse: 0.943527\tvalid_1's rmse: 0.945858\n",
      "[240]\ttraining's rmse: 0.929629\tvalid_1's rmse: 0.931963\n",
      "[260]\ttraining's rmse: 0.918191\tvalid_1's rmse: 0.920531\n",
      "[280]\ttraining's rmse: 0.907778\tvalid_1's rmse: 0.910125\n",
      "[300]\ttraining's rmse: 0.900584\tvalid_1's rmse: 0.903025\n",
      "[320]\ttraining's rmse: 0.894249\tvalid_1's rmse: 0.89672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/jc/xkd5blwd6hz99wjjbm45kwsw0000gn/T/ipykernel_1758/2224607395.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'valid'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     model, y_pred_valid, y_true = lgbm_fit(\n\u001B[0m\u001B[1;32m      8\u001B[0m         \u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m         \u001B[0mvalid_data\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/UniPassau/DSLab/ds-lab-21-22/helper_functions.py\u001B[0m in \u001B[0;36mlgbm_fit\u001B[0;34m(train, val, seed, cat_features, num_rounds, lr, bf)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'training LGB:'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     model = lgb.train(params,\n\u001B[0m\u001B[1;32m     39\u001B[0m                       \u001B[0mtrain_set\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0md_train\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m                       \u001B[0mnum_boost_round\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnum_rounds\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/UniPassau/DSLab/ds-lab-21-22/venv/lib/python3.9/site-packages/lightgbm/engine.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[1;32m    290\u001B[0m                                     evaluation_result_list=None))\n\u001B[1;32m    291\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m         \u001B[0mbooster\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfobj\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[0mevaluation_result_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/UniPassau/DSLab/ds-lab-21-22/venv/lib/python3.9/site-packages/lightgbm/basic.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, train_set, fobj)\u001B[0m\n\u001B[1;32m   3019\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__set_objective_to_none\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3020\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mLightGBMError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Cannot update due to null objective function.'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3021\u001B[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001B[0m\u001B[1;32m   3022\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3023\u001B[0m                 ctypes.byref(is_finished)))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for train_idx, valid_idx in kf_shuffled.split(X_train, y_train):\n",
    "    train_data = X_train.iloc[train_idx,:], y_train[train_idx]\n",
    "    valid_data = X_train.iloc[valid_idx,:], y_train[valid_idx]\n",
    "\n",
    "    print('train', len(train_idx), 'valid', len(valid_idx))\n",
    "    model, y_pred_valid, y_true = lgbm_fit(\n",
    "        train_data,\n",
    "        valid_data,\n",
    "        cat_features = category_columns,\n",
    "        num_rounds=1000,\n",
    "        lr = 0.04,\n",
    "        bf = 0.8\n",
    "    )\n",
    "    models.append(model)\n",
    "    del model, y_pred_valid, train_data, valid_data\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the trained model using the average of the models produced by cross-validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mae_scores = [model.best_score[\"valid_1\"][\"rmse\"] for model in models]\n",
    "avg_mae_score = np.average(mae_scores)\n",
    "print('RMSE: {0}'.format(avg_mae_score))\n",
    "\n",
    "# rmsle_scores = [model.best_score[\"valid_1\"][\"RMSLE\"] for model in models]\n",
    "# avg_rmsle_score = np.average(rmsle_scores)\n",
    "# print('RMSLE: {0}'.format(avg_rmsle_score))\n",
    "\n",
    "for index, model in enumerate(models):\n",
    "    model.save_model('./models/lgbm-base/lgbm_model_{0}.txt'.format(index))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Loading (Test dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_test_df = pd.read_feather(\"./data/test_full.feather\")\n",
    "sample_submission = pd.read_feather(\"./data/feather/sample_submission.feather\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction on test data"
   ],
   "metadata": {
    "id": "N-SY9Hk24hwr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X_test = full_test_df[feature_columns + category_columns]"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-01-05T15:12:20.048916Z",
     "iopub.execute_input": "2022-01-05T15:12:20.049306Z",
     "iopub.status.idle": "2022-01-05T15:12:20.056136Z",
     "shell.execute_reply.started": "2022-01-05T15:12:20.049236Z",
     "shell.execute_reply": "2022-01-05T15:12:20.054446Z"
    },
    "trusted": true,
    "id": "Ruvux8rK4hws",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_models = [lgb.Booster(model_file=f\"./models/lgbm-base/lgbm_model_{i}.txt\") for i in range(number_of_folds)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_test = lgbm_predict(X_test, loaded_models)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-05T15:12:20.072191Z",
     "iopub.execute_input": "2022-01-05T15:12:20.072508Z",
     "iopub.status.idle": "2022-01-05T15:21:24.595590Z",
     "shell.execute_reply.started": "2022-01-05T15:12:20.072454Z",
     "shell.execute_reply": "2022-01-05T15:21:24.594112Z"
    },
    "trusted": true,
    "id": "8Je-Qq1V4hws",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission['meter_reading'] = np.expm1(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission[sample_submission['meter_reading'] < 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission.loc[sample_submission['meter_reading'] < 0, 'meter_reading'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyse the result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "pd.DataFrame(y_test).hist(bins=20,color=\"#955586\")\n",
    "full_train_df['meter_reading_log1p'].hist(bins=20, color='#2E1F3F')\n",
    "plt.xlabel(\"Meter Readings\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Train/Test Meter Reading Distribution\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.log1p(sample_submission['meter_reading']).plot()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission[sample_submission['meter_reading'] == 0.0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save to submission.csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_submission.to_csv('./data/submissions/submission_base_lgbm.csv', index=False, float_format='%.4f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}